{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2ca65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8936472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tavishipriyam/Desktop/sem4/EVs/feather format\n"
     ]
    }
   ],
   "source": [
    "cd feather\\ format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6658851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/nlj2ws3n7mz6my6588wvrlsw0000gn/T/ipykernel_95178/2968492199.py:1: DtypeWarning: Columns (0,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"male_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"male_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f77e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7bae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7cb7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>attachments</th>\n",
       "      <th>author_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>withheld</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.324897e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:59:22+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @HackRead: On hacked TV transmissions #Anon...</td>\n",
       "      <td>{'created_at': '2020-11-07T02:10:57.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498381160380080135', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '411396541'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&lt;=18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.497817e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:59:15+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 108, 'normalize...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @softwarnet: #infosec \\nhttps://t.co/x5meu1...</td>\n",
       "      <td>{'created_at': '2022-02-27T06:12:17.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498342666546733056', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '4148621113...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.213556e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:58:48+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 94, 'normalized...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 3, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>A problem for electric vehicle owners? \"Anonym...</td>\n",
       "      <td>{'created_at': '2020-01-04T20:22:27.000Z', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.727390e+09</td>\n",
       "      <td>1.498391e+18</td>\n",
       "      <td>2022-02-28 23:58:40+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 34, 'normalized...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>@garyblack00 I can’t afford a Tesla right now ...</td>\n",
       "      <td>{'created_at': '2013-09-04T03:01:38.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498391412659953673', 'type': 'replie...</td>\n",
       "      <td>{'attachments': {'media_keys': array(['3_14983...</td>\n",
       "      <td>1.161704e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.378083e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:58:36+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 127, 'normalize...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @kathygpr: Remember: The previous admin was...</td>\n",
       "      <td>{'created_at': '2021-04-02T20:33:02.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498446693502623745', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '8204921770...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223382</th>\n",
       "      <td>53248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.025679e+18</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:57+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @LucidMotors: The longest range car of the ...</td>\n",
       "      <td>{'created_at': '2018-08-04T09:43:28.000Z', 'de...</td>\n",
       "      <td>[{'id': '1460217211100954624', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': {'media_keys': array(['13_1460...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223383</th>\n",
       "      <td>53249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.199569e+08</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:53+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @teamswiftparrot: I’m not a car guy, but at...</td>\n",
       "      <td>{'created_at': '2012-03-10T00:38:28.000Z', 'de...</td>\n",
       "      <td>[{'id': '1485520486369214464', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '2872961599...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&lt;=18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223384</th>\n",
       "      <td>53251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.484017e+18</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:46+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>Break-Through Ultra-Precision Machining Platfo...</td>\n",
       "      <td>{'created_at': '2022-01-20T04:17:10.000Z', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223385</th>\n",
       "      <td>53252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.586152e+07</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:45+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 31, 'normalized...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @hartfordcourant: Connecticut is embarking ...</td>\n",
       "      <td>{'created_at': '2009-07-11T16:04:56.000Z', 'de...</td>\n",
       "      <td>[{'id': '1485583832120180746', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '14708814',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223386</th>\n",
       "      <td>53253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.446882e+18</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:42+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 79, 'normalized...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @richjaguarz: To celebrate the announcement...</td>\n",
       "      <td>{'created_at': '2021-10-09T16:53:52.000Z', 'de...</td>\n",
       "      <td>[{'id': '1484194465451769858', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': {'media_keys': array(['3_14841...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223387 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 attachments     author_id  conversation_id  \\\n",
       "0               1         NaN  1.324897e+18     1.498448e+18   \n",
       "1               3         NaN  1.497817e+18     1.498448e+18   \n",
       "2               4         NaN  1.213556e+18     1.498448e+18   \n",
       "3               5         NaN  1.727390e+09     1.498391e+18   \n",
       "4               6         NaN  1.378083e+18     1.498448e+18   \n",
       "...           ...         ...           ...              ...   \n",
       "223382      53248         NaN  1.025679e+18     1.485585e+18   \n",
       "223383      53249         NaN  5.199569e+08     1.485585e+18   \n",
       "223384      53251         NaN  1.484017e+18     1.485585e+18   \n",
       "223385      53252         NaN  5.586152e+07     1.485585e+18   \n",
       "223386      53253         NaN  1.446882e+18     1.485585e+18   \n",
       "\n",
       "                       created_at  \\\n",
       "0       2022-02-28 23:59:22+00:00   \n",
       "1       2022-02-28 23:59:15+00:00   \n",
       "2       2022-02-28 23:58:48+00:00   \n",
       "3       2022-02-28 23:58:40+00:00   \n",
       "4       2022-02-28 23:58:36+00:00   \n",
       "...                           ...   \n",
       "223382  2022-01-24 12:07:57+00:00   \n",
       "223383  2022-01-24 12:07:53+00:00   \n",
       "223384  2022-01-24 12:07:46+00:00   \n",
       "223385  2022-01-24 12:07:45+00:00   \n",
       "223386  2022-01-24 12:07:42+00:00   \n",
       "\n",
       "                                                 entities            id lang  \\\n",
       "0       {'annotations': None, 'cashtags': None, 'hasht...  1.498448e+18   en   \n",
       "1       {'annotations': array([{'end': 108, 'normalize...  1.498448e+18   en   \n",
       "2       {'annotations': array([{'end': 94, 'normalized...  1.498448e+18   en   \n",
       "3       {'annotations': array([{'end': 34, 'normalized...  1.498448e+18   en   \n",
       "4       {'annotations': array([{'end': 127, 'normalize...  1.498448e+18   en   \n",
       "...                                                   ...           ...  ...   \n",
       "223382  {'annotations': None, 'cashtags': None, 'hasht...  1.485585e+18   en   \n",
       "223383  {'annotations': None, 'cashtags': None, 'hasht...  1.485585e+18   en   \n",
       "223384  {'annotations': None, 'cashtags': None, 'hasht...  1.485585e+18   en   \n",
       "223385  {'annotations': array([{'end': 31, 'normalized...  1.485585e+18   en   \n",
       "223386  {'annotations': array([{'end': 79, 'normalized...  1.485585e+18   en   \n",
       "\n",
       "                                           public_metrics  \\\n",
       "0       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "1       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "2       {'like_count': 3, 'quote_count': 0, 'reply_cou...   \n",
       "3       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "4       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "...                                                   ...   \n",
       "223382  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223383  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223384  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223385  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223386  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "\n",
       "                                                     text  \\\n",
       "0       RT @HackRead: On hacked TV transmissions #Anon...   \n",
       "1       RT @softwarnet: #infosec \\nhttps://t.co/x5meu1...   \n",
       "2       A problem for electric vehicle owners? \"Anonym...   \n",
       "3       @garyblack00 I can’t afford a Tesla right now ...   \n",
       "4       RT @kathygpr: Remember: The previous admin was...   \n",
       "...                                                   ...   \n",
       "223382  RT @LucidMotors: The longest range car of the ...   \n",
       "223383  RT @teamswiftparrot: I’m not a car guy, but at...   \n",
       "223384  Break-Through Ultra-Precision Machining Platfo...   \n",
       "223385  RT @hartfordcourant: Connecticut is embarking ...   \n",
       "223386  RT @richjaguarz: To celebrate the announcement...   \n",
       "\n",
       "                                                     user  \\\n",
       "0       {'created_at': '2020-11-07T02:10:57.000Z', 'de...   \n",
       "1       {'created_at': '2022-02-27T06:12:17.000Z', 'de...   \n",
       "2       {'created_at': '2020-01-04T20:22:27.000Z', 'de...   \n",
       "3       {'created_at': '2013-09-04T03:01:38.000Z', 'de...   \n",
       "4       {'created_at': '2021-04-02T20:33:02.000Z', 'de...   \n",
       "...                                                   ...   \n",
       "223382  {'created_at': '2018-08-04T09:43:28.000Z', 'de...   \n",
       "223383  {'created_at': '2012-03-10T00:38:28.000Z', 'de...   \n",
       "223384  {'created_at': '2022-01-20T04:17:10.000Z', 'de...   \n",
       "223385  {'created_at': '2009-07-11T16:04:56.000Z', 'de...   \n",
       "223386  {'created_at': '2021-10-09T16:53:52.000Z', 'de...   \n",
       "\n",
       "                                        referenced_tweets  \\\n",
       "0       [{'id': '1498381160380080135', 'type': 'retwee...   \n",
       "1       [{'id': '1498342666546733056', 'type': 'retwee...   \n",
       "2                                                     NaN   \n",
       "3       [{'id': '1498391412659953673', 'type': 'replie...   \n",
       "4       [{'id': '1498446693502623745', 'type': 'retwee...   \n",
       "...                                                   ...   \n",
       "223382  [{'id': '1460217211100954624', 'type': 'retwee...   \n",
       "223383  [{'id': '1485520486369214464', 'type': 'retwee...   \n",
       "223384                                                NaN   \n",
       "223385  [{'id': '1485583832120180746', 'type': 'retwee...   \n",
       "223386  [{'id': '1484194465451769858', 'type': 'retwee...   \n",
       "\n",
       "                                         retweeted_status  \\\n",
       "0       {'attachments': None, 'author_id': '411396541'...   \n",
       "1       {'attachments': None, 'author_id': '4148621113...   \n",
       "2                                                     NaN   \n",
       "3       {'attachments': {'media_keys': array(['3_14983...   \n",
       "4       {'attachments': None, 'author_id': '8204921770...   \n",
       "...                                                   ...   \n",
       "223382  {'attachments': {'media_keys': array(['13_1460...   \n",
       "223383  {'attachments': None, 'author_id': '2872961599...   \n",
       "223384                                                NaN   \n",
       "223385  {'attachments': None, 'author_id': '14708814',...   \n",
       "223386  {'attachments': {'media_keys': array(['3_14841...   \n",
       "\n",
       "        in_reply_to_user_id  geo withheld  context_annotations gender    age  \n",
       "0                       NaN  NaN      NaN                  NaN   male   <=18  \n",
       "1                       NaN  NaN      NaN                  NaN   male   >=40  \n",
       "2                       NaN  NaN      NaN                  NaN   male   >=40  \n",
       "3              1.161704e+18  NaN      NaN                  NaN   male   >=40  \n",
       "4                       NaN  NaN      NaN                  NaN   male   >=40  \n",
       "...                     ...  ...      ...                  ...    ...    ...  \n",
       "223382                  NaN  NaN      NaN                  NaN   male  30-39  \n",
       "223383                  NaN  NaN      NaN                  NaN   male   <=18  \n",
       "223384                  NaN  NaN      NaN                  NaN   male   >=40  \n",
       "223385                  NaN  NaN      NaN                  NaN   male  30-39  \n",
       "223386                  NaN  NaN      NaN                  NaN   male  30-39  \n",
       "\n",
       "[223387 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c43348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0bef97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['http','https','zpxvxdlj','co','rt','ev','evs','electric','car','vehicle','from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912e0098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: jinja2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (1.21.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: setuptools in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (58.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.2.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5275492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.26.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: setuptools in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (58.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.62.3)\n",
      "Requirement already satisfied: jinja2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d151a75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>attachments</th>\n",
       "      <th>author_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>withheld</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.324897e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:59:22+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @HackRead: On hacked TV transmissions #Anon...</td>\n",
       "      <td>{'created_at': '2020-11-07T02:10:57.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498381160380080135', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '411396541'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&lt;=18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.497817e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:59:15+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 108, 'normalize...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @softwarnet: #infosec \\nhttps://t.co/x5meu1...</td>\n",
       "      <td>{'created_at': '2022-02-27T06:12:17.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498342666546733056', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '4148621113...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.213556e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:58:48+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 94, 'normalized...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 3, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>A problem for electric vehicle owners? \"Anonym...</td>\n",
       "      <td>{'created_at': '2020-01-04T20:22:27.000Z', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.727390e+09</td>\n",
       "      <td>1.498391e+18</td>\n",
       "      <td>2022-02-28 23:58:40+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 34, 'normalized...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>@garyblack00 I can’t afford a Tesla right now ...</td>\n",
       "      <td>{'created_at': '2013-09-04T03:01:38.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498391412659953673', 'type': 'replie...</td>\n",
       "      <td>{'attachments': {'media_keys': array(['3_14983...</td>\n",
       "      <td>1.161704e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.378083e+18</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>2022-02-28 23:58:36+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 127, 'normalize...</td>\n",
       "      <td>1.498448e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @kathygpr: Remember: The previous admin was...</td>\n",
       "      <td>{'created_at': '2021-04-02T20:33:02.000Z', 'de...</td>\n",
       "      <td>[{'id': '1498446693502623745', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '8204921770...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223382</th>\n",
       "      <td>53248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.025679e+18</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:57+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @LucidMotors: The longest range car of the ...</td>\n",
       "      <td>{'created_at': '2018-08-04T09:43:28.000Z', 'de...</td>\n",
       "      <td>[{'id': '1460217211100954624', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': {'media_keys': array(['13_1460...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223383</th>\n",
       "      <td>53249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.199569e+08</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:53+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @teamswiftparrot: I’m not a car guy, but at...</td>\n",
       "      <td>{'created_at': '2012-03-10T00:38:28.000Z', 'de...</td>\n",
       "      <td>[{'id': '1485520486369214464', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '2872961599...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&lt;=18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223384</th>\n",
       "      <td>53251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.484017e+18</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:46+00:00</td>\n",
       "      <td>{'annotations': None, 'cashtags': None, 'hasht...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>Break-Through Ultra-Precision Machining Platfo...</td>\n",
       "      <td>{'created_at': '2022-01-20T04:17:10.000Z', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>&gt;=40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223385</th>\n",
       "      <td>53252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.586152e+07</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:45+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 31, 'normalized...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @hartfordcourant: Connecticut is embarking ...</td>\n",
       "      <td>{'created_at': '2009-07-11T16:04:56.000Z', 'de...</td>\n",
       "      <td>[{'id': '1485583832120180746', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': None, 'author_id': '14708814',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223386</th>\n",
       "      <td>53253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.446882e+18</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>2022-01-24 12:07:42+00:00</td>\n",
       "      <td>{'annotations': array([{'end': 79, 'normalized...</td>\n",
       "      <td>1.485585e+18</td>\n",
       "      <td>en</td>\n",
       "      <td>{'like_count': 0, 'quote_count': 0, 'reply_cou...</td>\n",
       "      <td>RT @richjaguarz: To celebrate the announcement...</td>\n",
       "      <td>{'created_at': '2021-10-09T16:53:52.000Z', 'de...</td>\n",
       "      <td>[{'id': '1484194465451769858', 'type': 'retwee...</td>\n",
       "      <td>{'attachments': {'media_keys': array(['3_14841...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>30-39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223387 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 attachments     author_id  conversation_id  \\\n",
       "0               1         NaN  1.324897e+18     1.498448e+18   \n",
       "1               3         NaN  1.497817e+18     1.498448e+18   \n",
       "2               4         NaN  1.213556e+18     1.498448e+18   \n",
       "3               5         NaN  1.727390e+09     1.498391e+18   \n",
       "4               6         NaN  1.378083e+18     1.498448e+18   \n",
       "...           ...         ...           ...              ...   \n",
       "223382      53248         NaN  1.025679e+18     1.485585e+18   \n",
       "223383      53249         NaN  5.199569e+08     1.485585e+18   \n",
       "223384      53251         NaN  1.484017e+18     1.485585e+18   \n",
       "223385      53252         NaN  5.586152e+07     1.485585e+18   \n",
       "223386      53253         NaN  1.446882e+18     1.485585e+18   \n",
       "\n",
       "                       created_at  \\\n",
       "0       2022-02-28 23:59:22+00:00   \n",
       "1       2022-02-28 23:59:15+00:00   \n",
       "2       2022-02-28 23:58:48+00:00   \n",
       "3       2022-02-28 23:58:40+00:00   \n",
       "4       2022-02-28 23:58:36+00:00   \n",
       "...                           ...   \n",
       "223382  2022-01-24 12:07:57+00:00   \n",
       "223383  2022-01-24 12:07:53+00:00   \n",
       "223384  2022-01-24 12:07:46+00:00   \n",
       "223385  2022-01-24 12:07:45+00:00   \n",
       "223386  2022-01-24 12:07:42+00:00   \n",
       "\n",
       "                                                 entities            id lang  \\\n",
       "0       {'annotations': None, 'cashtags': None, 'hasht...  1.498448e+18   en   \n",
       "1       {'annotations': array([{'end': 108, 'normalize...  1.498448e+18   en   \n",
       "2       {'annotations': array([{'end': 94, 'normalized...  1.498448e+18   en   \n",
       "3       {'annotations': array([{'end': 34, 'normalized...  1.498448e+18   en   \n",
       "4       {'annotations': array([{'end': 127, 'normalize...  1.498448e+18   en   \n",
       "...                                                   ...           ...  ...   \n",
       "223382  {'annotations': None, 'cashtags': None, 'hasht...  1.485585e+18   en   \n",
       "223383  {'annotations': None, 'cashtags': None, 'hasht...  1.485585e+18   en   \n",
       "223384  {'annotations': None, 'cashtags': None, 'hasht...  1.485585e+18   en   \n",
       "223385  {'annotations': array([{'end': 31, 'normalized...  1.485585e+18   en   \n",
       "223386  {'annotations': array([{'end': 79, 'normalized...  1.485585e+18   en   \n",
       "\n",
       "                                           public_metrics  \\\n",
       "0       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "1       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "2       {'like_count': 3, 'quote_count': 0, 'reply_cou...   \n",
       "3       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "4       {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "...                                                   ...   \n",
       "223382  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223383  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223384  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223385  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "223386  {'like_count': 0, 'quote_count': 0, 'reply_cou...   \n",
       "\n",
       "                                                     text  \\\n",
       "0       RT @HackRead: On hacked TV transmissions #Anon...   \n",
       "1       RT @softwarnet: #infosec \\nhttps://t.co/x5meu1...   \n",
       "2       A problem for electric vehicle owners? \"Anonym...   \n",
       "3       @garyblack00 I can’t afford a Tesla right now ...   \n",
       "4       RT @kathygpr: Remember: The previous admin was...   \n",
       "...                                                   ...   \n",
       "223382  RT @LucidMotors: The longest range car of the ...   \n",
       "223383  RT @teamswiftparrot: I’m not a car guy, but at...   \n",
       "223384  Break-Through Ultra-Precision Machining Platfo...   \n",
       "223385  RT @hartfordcourant: Connecticut is embarking ...   \n",
       "223386  RT @richjaguarz: To celebrate the announcement...   \n",
       "\n",
       "                                                     user  \\\n",
       "0       {'created_at': '2020-11-07T02:10:57.000Z', 'de...   \n",
       "1       {'created_at': '2022-02-27T06:12:17.000Z', 'de...   \n",
       "2       {'created_at': '2020-01-04T20:22:27.000Z', 'de...   \n",
       "3       {'created_at': '2013-09-04T03:01:38.000Z', 'de...   \n",
       "4       {'created_at': '2021-04-02T20:33:02.000Z', 'de...   \n",
       "...                                                   ...   \n",
       "223382  {'created_at': '2018-08-04T09:43:28.000Z', 'de...   \n",
       "223383  {'created_at': '2012-03-10T00:38:28.000Z', 'de...   \n",
       "223384  {'created_at': '2022-01-20T04:17:10.000Z', 'de...   \n",
       "223385  {'created_at': '2009-07-11T16:04:56.000Z', 'de...   \n",
       "223386  {'created_at': '2021-10-09T16:53:52.000Z', 'de...   \n",
       "\n",
       "                                        referenced_tweets  \\\n",
       "0       [{'id': '1498381160380080135', 'type': 'retwee...   \n",
       "1       [{'id': '1498342666546733056', 'type': 'retwee...   \n",
       "2                                                     NaN   \n",
       "3       [{'id': '1498391412659953673', 'type': 'replie...   \n",
       "4       [{'id': '1498446693502623745', 'type': 'retwee...   \n",
       "...                                                   ...   \n",
       "223382  [{'id': '1460217211100954624', 'type': 'retwee...   \n",
       "223383  [{'id': '1485520486369214464', 'type': 'retwee...   \n",
       "223384                                                NaN   \n",
       "223385  [{'id': '1485583832120180746', 'type': 'retwee...   \n",
       "223386  [{'id': '1484194465451769858', 'type': 'retwee...   \n",
       "\n",
       "                                         retweeted_status  \\\n",
       "0       {'attachments': None, 'author_id': '411396541'...   \n",
       "1       {'attachments': None, 'author_id': '4148621113...   \n",
       "2                                                     NaN   \n",
       "3       {'attachments': {'media_keys': array(['3_14983...   \n",
       "4       {'attachments': None, 'author_id': '8204921770...   \n",
       "...                                                   ...   \n",
       "223382  {'attachments': {'media_keys': array(['13_1460...   \n",
       "223383  {'attachments': None, 'author_id': '2872961599...   \n",
       "223384                                                NaN   \n",
       "223385  {'attachments': None, 'author_id': '14708814',...   \n",
       "223386  {'attachments': {'media_keys': array(['3_14841...   \n",
       "\n",
       "        in_reply_to_user_id  geo withheld  context_annotations gender    age  \n",
       "0                       NaN  NaN      NaN                  NaN   male   <=18  \n",
       "1                       NaN  NaN      NaN                  NaN   male   >=40  \n",
       "2                       NaN  NaN      NaN                  NaN   male   >=40  \n",
       "3              1.161704e+18  NaN      NaN                  NaN   male   >=40  \n",
       "4                       NaN  NaN      NaN                  NaN   male   >=40  \n",
       "...                     ...  ...      ...                  ...    ...    ...  \n",
       "223382                  NaN  NaN      NaN                  NaN   male  30-39  \n",
       "223383                  NaN  NaN      NaN                  NaN   male   <=18  \n",
       "223384                  NaN  NaN      NaN                  NaN   male   >=40  \n",
       "223385                  NaN  NaN      NaN                  NaN   male  30-39  \n",
       "223386                  NaN  NaN      NaN                  NaN   male  30-39  \n",
       "\n",
       "[223387 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c11b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52157\n",
      "52158\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataa)):\n",
    "    if type(dataa[i])!= str:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13439f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataa[52158]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7965a601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rt', 'on', 'hacked', 'tv', 'transmissions', 'anonymous', 'displayed', 'the', 'national', 'anthem', 'of', 'ukraine', 'while', 'another', 'video', 'shows', 'an', 'electric', 'vehicl']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        if type(sent)!= str:\n",
    "            continue\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  \n",
    "\n",
    "# Convert to list\n",
    "dataa = data.text.values.tolist()\n",
    "data_words = list(sent_to_words(dataa))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2f0ccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b136d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "746ec629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.088*\"charge\" + 0.059*\"station\" + 0.053*\"pace\" + 0.050*\"holder\" + '\n",
      "  '0.050*\"giveaway\" + 0.050*\"giving_away\" + 0.050*\"celebrate\" + '\n",
      "  '0.048*\"announcement\" + 0.035*\"amp\" + 0.017*\"competition\"'),\n",
      " (1,\n",
      "  '0.076*\"tesla\" + 0.042*\"invest\" + 0.042*\"company\" + 0.035*\"state\" + '\n",
      "  '0.034*\"today\" + 0.031*\"announce\" + 0.025*\"well\" + 0.023*\"gtq_tngpta\" + '\n",
      "  '0.019*\"jaguar\" + 0.017*\"win\"'),\n",
      " (2,\n",
      "  '0.042*\"first\" + 0.041*\"new\" + 0.027*\"shodlurhj\" + 0.026*\"truck\" + '\n",
      "  '0.021*\"year\" + 0.017*\"next\" + 0.012*\"future\" + 0.012*\"sale\" + '\n",
      "  '0.011*\"production\" + 0.010*\"hybrid\"'),\n",
      " (3,\n",
      "  '0.057*\"battery\" + 0.015*\"drive\" + 0.014*\"power\" + 0.013*\"price\" + '\n",
      "  '0.012*\"buy\" + 0.011*\"gas\" + 0.011*\"replacement\" + 0.010*\"lithium\" + '\n",
      "  '0.010*\"pay\" + 0.008*\"demand\"')]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=10,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26889b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ae2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lens = [len(d) for d in df_dominant_topic.Text]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16,7), dpi=160)\n",
    "plt.hist(doc_lens, bins = 1000, color='navy')\n",
    "plt.text(750, 100, \"Mean   : \" + str(round(np.mean(doc_lens))))\n",
    "plt.text(750,  90, \"Median : \" + str(round(np.median(doc_lens))))\n",
    "plt.text(750,  80, \"Stdev   : \" + str(round(np.std(doc_lens))))\n",
    "plt.text(750,  70, \"1%ile    : \" + str(round(np.quantile(doc_lens, q=0.01))))\n",
    "plt.text(750,  60, \"99%ile  : \" + str(round(np.quantile(doc_lens, q=0.99))))\n",
    "\n",
    "plt.gca().set(xlim=(0, 1000), ylabel='Number of Documents', xlabel='Document Word Count')\n",
    "plt.tick_params(size=16)\n",
    "plt.xticks(np.linspace(0,1000,9))\n",
    "plt.title('Distribution of Document Word Counts', fontdict=dict(size=22))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(16,14), dpi=160, sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):    \n",
    "    df_dominant_topic_sub = df_dominant_topic.loc[df_dominant_topic.Dominant_Topic == i, :]\n",
    "    doc_lens = [len(d) for d in df_dominant_topic_sub.Text]\n",
    "    ax.hist(doc_lens, bins = 1000, color=cols[i])\n",
    "    ax.tick_params(axis='y', labelcolor=cols[i], color=cols[i])\n",
    "    sns.kdeplot(doc_lens, color=\"black\", shade=False, ax=ax.twinx())\n",
    "    ax.set(xlim=(0, 1000), xlabel='Document Word Count')\n",
    "    ax.set_ylabel('Number of Documents', color=cols[i])\n",
    "    ax.set_title('Topic: '+str(i), fontdict=dict(size=16, color=cols[i]))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.90)\n",
    "plt.xticks(np.linspace(0,1000,9))\n",
    "fig.suptitle('Distribution of Document Word Counts by Dominant Topic', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c00a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "data_flat = [w for w_list in data_ready for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f82f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def sentences_chart(lda_model=lda_model, corpus=corpus, start = 0, end = 13):\n",
    "    corp = corpus[start:end]\n",
    "    mycolors = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "    fig, axes = plt.subplots(end-start, 1, figsize=(20, (end-start)*0.95), dpi=160)       \n",
    "    axes[0].axis('off')\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i > 0:\n",
    "            corp_cur = corp[i-1] \n",
    "            topic_percs, wordid_topics, wordid_phivalues = lda_model[corp_cur]\n",
    "            word_dominanttopic = [(lda_model.id2word[wd], topic[0]) for wd, topic in wordid_topics]    \n",
    "            ax.text(0.01, 0.5, \"Doc \" + str(i-1) + \": \", verticalalignment='center',\n",
    "                    fontsize=16, color='black', transform=ax.transAxes, fontweight=700)\n",
    "\n",
    "            # Draw Rectange\n",
    "            topic_percs_sorted = sorted(topic_percs, key=lambda x: (x[1]), reverse=True)\n",
    "            ax.add_patch(Rectangle((0.0, 0.05), 0.99, 0.90, fill=None, alpha=1, \n",
    "                                   color=mycolors[topic_percs_sorted[0][0]], linewidth=2))\n",
    "\n",
    "            word_pos = 0.06\n",
    "            for j, (word, topics) in enumerate(word_dominanttopic):\n",
    "                if j < 14:\n",
    "                    ax.text(word_pos, 0.5, word,\n",
    "                            horizontalalignment='left',\n",
    "                            verticalalignment='center',\n",
    "                            fontsize=16, color=mycolors[topics],\n",
    "                            transform=ax.transAxes, fontweight=700)\n",
    "                    word_pos += .009 * len(word)  # to move the word for the next iter\n",
    "                    ax.axis('off')\n",
    "            ax.text(word_pos, 0.5, '. . .',\n",
    "                    horizontalalignment='left',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=16, color='black',\n",
    "                    transform=ax.transAxes)       \n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.suptitle('Sentence Topic Coloring for Documents: ' + str(start) + ' to ' + str(end-2), fontsize=22, y=0.95, fontweight=700)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_chart()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_per_document(model, corpus, start=0, end=1):\n",
    "    corpus_sel = corpus[start:end]\n",
    "    dominant_topics = []\n",
    "    topic_percentages = []\n",
    "    for i, corp in enumerate(corpus_sel):\n",
    "        topic_percs, wordid_topics, wordid_phivalues = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        topic_percentages.append(topic_percs)\n",
    "    return(dominant_topics, topic_percentages)\n",
    "\n",
    "dominant_topics, topic_percentages = topics_per_document(model=lda_model, corpus=corpus, end=-1)            \n",
    "\n",
    "# Distribution of Dominant Topics in Each Document\n",
    "df = pd.DataFrame(dominant_topics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "dominant_topic_in_each_doc = df.groupby('Dominant_Topic').size()\n",
    "df_dominant_topic_in_each_doc = dominant_topic_in_each_doc.to_frame(name='count').reset_index()\n",
    "\n",
    "# Total Topic Distribution by actual weight\n",
    "topic_weightage_by_doc = pd.DataFrame([dict(t) for t in topic_percentages])\n",
    "df_topic_weightage_by_doc = topic_weightage_by_doc.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# Top 3 Keywords for each Topic\n",
    "topic_top3words = [(i, topic) for i, topics in lda_model.show_topics(formatted=False) \n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "df_top3words_stacked = pd.DataFrame(topic_top3words, columns=['topic_id', 'words'])\n",
    "df_top3words = df_top3words_stacked.groupby('topic_id').agg(', \\n'.join)\n",
    "df_top3words.reset_index(level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), dpi=120, sharey=True)\n",
    "\n",
    "# Topic Distribution by Dominant Topics\n",
    "ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.5, color='firebrick')\n",
    "ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])\n",
    "ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size=10))\n",
    "ax1.set_ylabel('Number of Documents')\n",
    "# ax1.set_ylim(0, 1000)\n",
    "\n",
    "# Topic Distribution by Topic Weights\n",
    "ax2.bar(x='index', height='count', data=df_topic_weightage_by_doc, width=.5, color='steelblue')\n",
    "ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))\n",
    "ax2.xaxis.set_major_formatter(tick_formatter)\n",
    "ax2.set_title('Number of Documents by Topic Weightage', fontdict=dict(size=10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(lda_model[corpus]):\n",
    "    topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 4\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "              plot_width=900, plot_height=700)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37210ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bokeh in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (1.21.4)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (3.1.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (8.4.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (2022.9.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (1.0.6)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (6.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (6.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from bokeh) (21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from Jinja2>=2.9->bokeh) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from packaging>=16.8->bokeh) (3.0.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from pandas>=1.2->bokeh) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2->bokeh) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3efc444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'gensim' from 'pyLDAvis' (/Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages/pyLDAvis/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gensim\n\u001b[1;32m      4\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[1;32m      5\u001b[0m vis \u001b[38;5;241m=\u001b[39m gensim\u001b[38;5;241m.\u001b[39mprepare(lda_model, corpus, dictionary\u001b[38;5;241m=\u001b[39mlda_model\u001b[38;5;241m.\u001b[39mid2word)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'gensim' from 'pyLDAvis' (/Users/tavishipriyam/Downloads/ENTER/lib/python3.9/site-packages/pyLDAvis/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis import gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc0200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
